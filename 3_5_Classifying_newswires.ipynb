{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Classifying newswires : a multiclass classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.1 The Reuters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll work with the Reuters dataset, a set of short newswires and their topics, published\n",
    "by Reuters in 1986. It’s a simple, widely used toy dataset for text classification. There\n",
    "are 46 different topics; some topics are more represented than others, but each topic\n",
    "has at least 10 examples in the training set.\n",
    "\n",
    "Like IMDB and MNIST, the Reuters dataset comes packaged as part of Keras. Let’s\n",
    "take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 4s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# Loading the Reuters dataset\n",
    "from keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the IMDB dataset, the argument num_words=10000 restricts the data to the\n",
    "10,000 most frequently occurring words found in the data.\n",
    "\n",
    "You have 8,982 training examples and 2,246 test examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the IMDB reviews, each example is a list of integers (word indices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s how you can decode it back to words, in case you’re curious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 2s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# Decoding newswires back to text\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label associated with an example is an integer between 0 and 45—a topic index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.2 Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can vectorize the data with the exact same code as in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the data\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To vectorize the labels, there are two possibilities: you can cast the label list as an integer\n",
    "tensor, or you can use one-hot encoding. One-hot encoding is a widely used format\n",
    "for categorical data, also called __categorical encoding__. For a more detailed\n",
    "explanation of one-hot encoding, see section 6.1. In this case, one-hot encoding of\n",
    "the labels consists of embedding each label as an all-zero vector with a 1 in the place of\n",
    "the label index. Here’s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is a built-in way to do this in Keras, which you’ve already seen in action\n",
    "in the MNIST example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.3 Building your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This topic-classification problem looks similar to the previous movie-review classification\n",
    "problem: in both cases, you’re trying to classify short snippets of text. But there is\n",
    "a new constraint here: the number of output classes has gone from 2 to 46. The\n",
    "dimensionality of the output space is much larger.\n",
    "\n",
    "In a stack of __Dense__ layers like that you’ve been using, each layer can only access information\n",
    "present in the output of the previous layer. If one layer drops some information relevant to the classification problem, this information can never be recovered by later layers: each layer can potentially become an information bottleneck. In the previous example, you used 16-dimensional intermediate layers, but a 16-dimensional space may be too limited to learn to separate 46 different classes: such small layers may act as information bottlenecks, permanently dropping relevant information.\n",
    "\n",
    "For this reason you’ll use larger layers. Let’s go with 64 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yannickr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two other things you should note about this architecture:\n",
    "* You end the network with a Dense layer of size 46. This means for each input sample, the network will output a 46-dimensional vector. Each entry in this vector (each dimension) will encode a different output class.\n",
    "* The last layer uses a softmax activation. You saw this pattern in the MNIST example. It means the network will output a probability distribution over the 46 different output classes—for every input sample, the network will produce a 46-dimensional output vector, where __output[i]__ is the probability that the sample belongs to class __i__. The 46 scores will sum to 1.\n",
    "\n",
    "The best loss function to use in this case is __categorical_crossentropy__. It measures\n",
    "the distance between two probability distributions: here, between the probability distribution\n",
    "output by the network and the true distribution of the labels. By minimizing\n",
    "the distance between these two distributions, you train the network to output something\n",
    "as close as possible to the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.4 Validating your approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s set apart 1,000 samples in the training data to use as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting aside a validation set\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s train the network for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yannickr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 3s 369us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7204 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s 250us/step - loss: 1.4450 - acc: 0.6878 - val_loss: 1.3457 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 2s 255us/step - loss: 1.0951 - acc: 0.7648 - val_loss: 1.1704 - val_acc: 0.7420\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.8695 - acc: 0.8161 - val_loss: 1.0795 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 0.7032 - acc: 0.8480 - val_loss: 0.9846 - val_acc: 0.7820\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s 245us/step - loss: 0.5665 - acc: 0.8795 - val_loss: 0.9409 - val_acc: 0.8030\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s 246us/step - loss: 0.4580 - acc: 0.9049 - val_loss: 0.9074 - val_acc: 0.8010\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 0.3696 - acc: 0.9228 - val_loss: 0.9349 - val_acc: 0.7900\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 2s 248us/step - loss: 0.3032 - acc: 0.9311 - val_loss: 0.8917 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 2s 248us/step - loss: 0.2538 - acc: 0.9412 - val_loss: 0.9065 - val_acc: 0.8120\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 0.2183 - acc: 0.9470 - val_loss: 0.9177 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 2s 250us/step - loss: 0.1872 - acc: 0.9509 - val_loss: 0.9022 - val_acc: 0.8160\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 2s 255us/step - loss: 0.1698 - acc: 0.9525 - val_loss: 0.9341 - val_acc: 0.8090\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s 246us/step - loss: 0.1531 - acc: 0.9557 - val_loss: 0.9720 - val_acc: 0.8060\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.1390 - acc: 0.9557 - val_loss: 0.9691 - val_acc: 0.8140\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 2s 248us/step - loss: 0.1312 - acc: 0.9560 - val_loss: 1.0251 - val_acc: 0.8050\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s 243us/step - loss: 0.1215 - acc: 0.9579 - val_loss: 1.0256 - val_acc: 0.7960\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.1198 - acc: 0.9577 - val_loss: 1.0436 - val_acc: 0.8080\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s 246us/step - loss: 0.1137 - acc: 0.9594 - val_loss: 1.0935 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s 247us/step - loss: 0.1108 - acc: 0.9598 - val_loss: 1.0656 - val_acc: 0.8010\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let’s display its loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network begins to overfit after nine epochs. Let’s train a new network from scratch for nine epochs and then evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 325us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 2s 247us/step - loss: 1.3712 - acc: 0.7121 - val_loss: 1.2758 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 1.0136 - acc: 0.7781 - val_loss: 1.1303 - val_acc: 0.7530\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 2s 250us/step - loss: 0.7976 - acc: 0.8251 - val_loss: 1.0539 - val_acc: 0.7590\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 2s 251us/step - loss: 0.6393 - acc: 0.8624 - val_loss: 0.9754 - val_acc: 0.7920\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 2s 246us/step - loss: 0.5124 - acc: 0.8923 - val_loss: 0.9102 - val_acc: 0.8140\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 2s 248us/step - loss: 0.4123 - acc: 0.9137 - val_loss: 0.8932 - val_acc: 0.8210\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 2s 249us/step - loss: 0.3354 - acc: 0.9288 - val_loss: 0.8732 - val_acc: 0.8260\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 2s 250us/step - loss: 0.2782 - acc: 0.9371 - val_loss: 0.9337 - val_acc: 0.8010\n",
      "2246/2246 [==============================] - 1s 252us/step\n"
     ]
    }
   ],
   "source": [
    "# Retraining a model from scratch\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.022208026977702, 0.7756010686194165]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach reaches an accuracy of ~80%. With a balanced binary classification\n",
    "problem, the accuracy reached by a purely random classifier would be 50%. But in\n",
    "this case it’s closer to 19%, so the results seem pretty good, at least when compared to\n",
    "a random baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.182546749777382"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "float(np.sum(hits_array)) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.5 Generating predictions on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that the __predict__ method of the model instance returns a probability\n",
    "distribution over all 46 topics. Let’s generate topic predictions for all of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions for new data\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each entry in predictions is a vector of length 46:\n",
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The coefficients in this vector sum to 1:\n",
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The largest entry is the predicted class—the class with the highest probability:\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.6 A different way to handle the labels and the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned earlier that another way to encode the labels would be to cast them as an integer tensor, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing this approach would change is the choice of the loss function. The loss\n",
    "function used in listing 3.21, categorical_crossentropy, expects the labels to follow\n",
    "a categorical encoding. With integer labels, you should use sparse_categorical_\n",
    "crossentropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new loss function is still mathematically the same as __categorical_crossentropy__;\n",
    "it just has a different interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.7 The importance of having sufficiently large intermediate layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 4s 453us/step - loss: 2.6576 - acc: 0.3773 - val_loss: 1.9683 - val_acc: 0.5280\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 3s 342us/step - loss: 1.6652 - acc: 0.6208 - val_loss: 1.5408 - val_acc: 0.6230\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 3s 346us/step - loss: 1.3322 - acc: 0.6706 - val_loss: 1.3942 - val_acc: 0.6790\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 3s 347us/step - loss: 1.1418 - acc: 0.7275 - val_loss: 1.3251 - val_acc: 0.6960\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 3s 344us/step - loss: 1.0106 - acc: 0.7457 - val_loss: 1.2708 - val_acc: 0.7010\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 3s 343us/step - loss: 0.9093 - acc: 0.7578 - val_loss: 1.2763 - val_acc: 0.7080\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 3s 346us/step - loss: 0.8299 - acc: 0.7744 - val_loss: 1.2599 - val_acc: 0.7110\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 3s 338us/step - loss: 0.7687 - acc: 0.7902 - val_loss: 1.2650 - val_acc: 0.7180\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 3s 340us/step - loss: 0.7130 - acc: 0.8011 - val_loss: 1.2970 - val_acc: 0.7080\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 3s 337us/step - loss: 0.6622 - acc: 0.8113 - val_loss: 1.3282 - val_acc: 0.7100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 3s 348us/step - loss: 0.6172 - acc: 0.8183 - val_loss: 1.3556 - val_acc: 0.7090\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 3s 347us/step - loss: 0.5789 - acc: 0.8326 - val_loss: 1.3899 - val_acc: 0.7100\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 3s 350us/step - loss: 0.5411 - acc: 0.8435 - val_loss: 1.4490 - val_acc: 0.7080\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 3s 347us/step - loss: 0.5089 - acc: 0.8544 - val_loss: 1.4730 - val_acc: 0.7150\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 3s 340us/step - loss: 0.4786 - acc: 0.8664 - val_loss: 1.5195 - val_acc: 0.7160\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 3s 340us/step - loss: 0.4493 - acc: 0.8785 - val_loss: 1.5545 - val_acc: 0.7040\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 3s 345us/step - loss: 0.4263 - acc: 0.8819 - val_loss: 1.5759 - val_acc: 0.7080\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 3s 338us/step - loss: 0.4040 - acc: 0.8910 - val_loss: 1.6320 - val_acc: 0.7130\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 3s 336us/step - loss: 0.3843 - acc: 0.8936 - val_loss: 1.6693 - val_acc: 0.7120\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 3s 344us/step - loss: 0.3669 - acc: 0.8973 - val_loss: 1.7527 - val_acc: 0.7110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b105272358>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A model with an information bottleneck\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network now peaks at ~89% validation accuracy, an 4% absolute drop. This drop\n",
    "is mostly due to the fact that you’re trying to compress a lot of information (enough\n",
    "information to recover the separation hyperplanes of 46 classes) into an intermediate\n",
    "space that is too low-dimensional. The network is able to cram most of the necessary\n",
    "information into these eight-dimensional representations, but not all of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.8 Further experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try using larger or smaller layers: 32 units, 128 units, and so on.\n",
    "* You used two hidden layers. Now try using a single hidden layer, or three hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.9 Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s what you should take away from this example:\n",
    "* If you’re trying to classify data points among N classes, your network should end with a __Dense__ layer of size N.\n",
    "* In a single-label, multiclass classification problem, your network should end with a __softmax__ activation so that it will output a probability distribution over the N output classes.\n",
    "* __Categorical crossentropy__ is almost always the loss function you should use for such problems. It minimizes the distance between the probability distributions output by the network and the true distribution of the targets.\n",
    "* There are two ways to handle labels in __multiclass classification__: \n",
    "  - Encoding the labels via __categorical encoding__ (also known as one-hot encoding) and using __categorical_crossentropy as a loss function__, \n",
    "  - Encoding the labels as __integers__ and using the __sparse_categorical_crossentropy loss function__\n",
    "* If you need to classify data into a large number of categories, you should avoid creating __information bottlenecks__ in your network __due to intermediate layers that are too small__."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
