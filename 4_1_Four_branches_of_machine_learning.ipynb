{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Four branches of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous examples, you’ve become familiar with three specific types of\n",
    "machine-learning problems: binary classification, multiclass classification, and scalar\n",
    "regression. All three are instances of __supervised learning__, where the goal is to learn the\n",
    "relationship between training inputs and training targets.\n",
    "\n",
    "Supervised learning is just the tip of the iceberg—machine learning is a vast field\n",
    "with a complex subfield taxonomy. Machine-learning algorithms generally fall into\n",
    "four broad categories, described in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is by far the most common case. It consists of learning to map input data to\n",
    "known targets (also called __annotations__), given a set of examples (often annotated by\n",
    "humans). All four examples you’ve encountered in this book so far were canonical\n",
    "examples of supervised learning. Generally, almost all applications of deep learning\n",
    "that are in the spotlight these days belong in this category, such as optical character\n",
    "recognition, speech recognition, image classification, and language translation.\n",
    "\n",
    "Although supervised learning mostly consists of classification and regression, there\n",
    "are more exotic variants as well, including the following (with examples):\n",
    "\n",
    "* __Sequence generation__—Given a picture, predict a caption describing it. Sequence generation can sometimes be reformulated as a series of classification problems (such as repeatedly predicting a word or token in a sequence).\n",
    "* __Syntax tree prediction__—Given a sentence, predict its decomposition into a syntax tree.\n",
    "* __Object detection__—Given a picture, draw a bounding box around certain objects inside the picture. This can also be expressed as a classification problem (given many candidate bounding boxes, classify the contents of each one) or as a joint classification and regression problem, where the bounding-box coordinates are predicted via vector regression.\n",
    "* __Image segmentation__—Given a picture, draw a pixel-level mask on a specific object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This branch of machine learning consists of finding interesting transformations of the\n",
    "input data without the help of any targets, for the purposes of data visualization, data\n",
    "compression, or data denoising, or to better understand the correlations present in\n",
    "the data at hand. Unsupervised learning is __the bread and butter of data analytics__, and\n",
    "it’s often a __necessary step in better understanding a dataset before attempting to solve\n",
    "a supervised-learning problem__. __Dimensionality reduction__ and __clustering__ are well-known\n",
    "categories of unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 Self-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a specific instance of supervised learning, but it’s different enough that it\n",
    "deserves its own category. Self-supervised learning is supervised learning without human-annotated labels—you can think of it as supervised learning without any humans in the loop. There are still labels involved (because the learning has to be\n",
    "supervised by something), but they’re generated from the input data, typically using a\n",
    "heuristic algorithm.\n",
    "\n",
    "For instance, __autoencoders__ are a well-known instance of self-supervised learning,\n",
    "where the generated targets are the input, unmodified. In the same way, trying to predict\n",
    "the next frame in a video, given past frames, or the next word in a text, given previous\n",
    "words, are instances of self-supervised learning (temporally supervised learning, in this\n",
    "case: supervision comes from future input data). Note that the distinction between\n",
    "supervised, self-supervised, and unsupervised learning can be blurry sometimes—these\n",
    "categories are more of a continuum without solid borders. Self-supervised learning can\n",
    "be reinterpreted as either supervised or unsupervised learning, depending on whether\n",
    "you pay attention to the learning mechanism or to the context of its application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.4 Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long overlooked, this branch of machine learning recently started to get a lot of\n",
    "attention after Google DeepMind successfully applied it to learning to play Atari\n",
    "games (and, later, learning to play Go at the highest level). In reinforcement learning,\n",
    "an __agent__ receives information about its environment and learns to choose actions that\n",
    "will maximize some reward. For instance, a neural network that “looks” at a videogame\n",
    "screen and outputs game actions in order to maximize its score can be trained\n",
    "via reinforcement learning.\n",
    "\n",
    "Currently, reinforcement learning is mostly a research area and hasn’t yet had significant\n",
    "practical successes beyond games. In time, however, we expect to see reinforcement\n",
    "learning take over an increasingly large range of real-world applications:\n",
    "self-driving cars, robotics, resource management, education, and so on. It’s an idea\n",
    "whose time has come, or will come soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and regression glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and regression involve many specialized terms. You’ve come across\n",
    "some of them in earlier examples, and you’ll see more of them in future chapters.\n",
    "They have precise, machine-learning-specific definitions, and you should be familiar\n",
    "with them:\n",
    "* __Sample or input__—One data point that goes into your model.\n",
    "* __Prediction or output__—What comes out of your model.\n",
    "* __Target__—The truth. What your model should ideally have predicted, according to an external source of data.\n",
    "* __Prediction error or loss value__—A measure of the distance between your model’s prediction and the target.\n",
    "* __Classes__—A set of possible labels to choose from in a classification problem. For example, when classifying cat and dog pictures, “dog” and “cat” are the two classes.\n",
    "* __Label__—A specific instance of a class annotation in a classification problem. For instance, if picture #1234 is annotated as containing the class “dog,” then “dog” is a label of picture #1234.\n",
    "* __Ground-truth or annotations__—All targets for a dataset, typically collected by humans.\n",
    "* __Binary classification__—A classification task where each input sample should be categorized into two exclusive categories.\n",
    "* __Multiclass classification__—A classification task where each input sample should be categorized into more than two categories: for instance, classifying handwritten digits.\n",
    "* __Multilabel classification__—A classification task where each input sample can be assigned multiple labels. For instance, a given image may contain both a cat and a dog and should be annotated both with the “cat” label and the “dog” label. The number of labels per image is usually variable.\n",
    "* __Scalar regression__—A task where the target is a continuous scalar value. Predicting house prices is a good example: the different target prices form a continuous space.\n",
    "* __Vector regression__—A task where the target is a set of continuous values: for example, a continuous vector. If you’re doing regression against multiple values (such as the coordinates of a bounding box in an image), then you’re doing vector regression.\n",
    "* __Mini-batch or batch__—A small set of samples (typically between 8 and 128) that are processed simultaneously by the model. The number of samples is often a power of 2, to facilitate memory allocation on GPU. When training, a mini-batch is used to compute a single gradient-descent update applied to the weights of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
